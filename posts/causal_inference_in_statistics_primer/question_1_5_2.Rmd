---
title: "CIS Primer Question 1.5.2"
author: "Brian Callander"
date: "2019-02-10"
tags: CISP chapter 1, solutions, simpsons reversal, product decomposition
tldr: Here are my solutions to question 1.5.2 of Causal Inference in Statistics a Primer (CISP).
always_allow_html: yes
output: 
  md_document:
    variant: markdown
    preserve_yaml: yes
---

Here are my solutions to question 1.5.2 of Causal Inference in Statistics: a Primer (CISP).

<!--more-->

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  comment = NA,
  message = FALSE,
  warning = FALSE,
  error = TRUE,
  # cache = TRUE,
  dev = "svglite"
)

library(tidyverse)
library(scales)
library(kableExtra)
library(colorspace)

theme_set(theme_bw())
 
```

I'll use different indexing to make the notation clearer.  In particular, the indices will match the values of the conditioning variables.  

## Part a

The full joint probability is 

$$
\mathbb P(x, y, z)
=
\mathbb P (z) \cdot \mathbb P (x \mid z) \cdot \mathbb P (y \mid x, z)
$$

using the decomposition formula. Each factor is given by

$$
\begin{align}
  \mathbb P (z) 
  &=
  z r + (1 - z) (1 - r)
  \\
  \mathbb P (x \mid z) 
  &=
  xq_z + (1 - x)(1 - q_z)
  \\
  \mathbb P (y \mid x, z)
  &=
  yp_{x, z} + (1 - y)(1 - p_{x, z})
\end{align}
$$

where each parameter is assumed to have support on $\{0, 1\}$. 

The marginal distributions are given by

$$
\begin{align}
  \mathbb P(x, z)
  &=
  \mathbb P(x \mid z) \cdot \mathbb P (z)
  \\
  \mathbb P(y, z)
  &=
  \mathbb P(0, y, z) + \mathbb P(1, y, z)
  \\
  \mathbb P(x, y)
  &=
  \mathbb P(x, y, 0) + \mathbb P(x, y, 1)
  \\
  &=
  yp_{x, 0} + (1 - y)(1 - p_{x, 0})
  +
  yp_{x, 1} + (1 - y)(1 - p_{x, 1})
  \\
  &=
  y (p_{x, 0} + p_{x, 1})  + (1 - y)(2 - p_{x, 0} - p_{x, 1})
  .
\end{align}
$$

Furthermore,

$$
\begin{align}
  \mathbb P (x) 
  &=
  \sum_z \mathbb P(x \mid z) \mathbb P (z)
  \\
  &=
  \sum_z (xq_z + (1 - x)(1 - q_z))(zr + (1 - z)(1 - r))
\end{align}
$$

so that

$$
\begin{align}
  \mathbb P(X = 0)
  &=
  (1 - q_0)(1 - r) + (1 - q_1)r
  \\
  \mathbb P(X = 1)
  &=
  q_0(1 - r) + q_1r
\end{align}
$$

## Part b

The increase in probability from taking the drug in each sub-population is:

* $\mathbb P(y = 1 \mid x = 1, z = 0) - \mathbb P(y = 1 \mid x = 0, z = 0) = p_{1, 0} - p_{0, 0}$; and
* $\mathbb P(y = 1 \mid x = 1, z = 1) - \mathbb P(y = 1 \mid x = 0, z = 1) = p_{1, 1} - p_{0, 1}$.

In the whole population, the increase is $\mathbb P(Y = 1 \mid X = 1) - \mathbb P(Y = 1 \mid X = 0)$, calcualted via

$$
\begin{align}
  &
  \sum_{z = 0}^1 
  \mathbb P(Y = 1, Z = z \mid X = 1) - \mathbb P(Y = 1, Z = z \mid X = 0)
  \\
  &=
  \sum_{z = 0}^1 
  \frac{\mathbb P(X = 1, Y = 1, Z = z)}{\mathbb P(X = 1)} - \frac{\mathbb P(X = 0, Y = 1, Z = z)}{\mathbb P(X = 0)}
  \\
  &=
  \frac{(1 - r)q_0p_{1, 0} + rq_1p_{1, 1}}{q_0(1 - r) + q_1r} 
  - 
  \frac{(1 - r)(1 - q_0)p_{0, 0} + r(1 - q_1)p_{0, 1}}{(1 - q_0)(1 - r) + (1 - q_1)r}
\end{align}
$$

## Part c

There's no need to be smart about this. Let's just simulate lots of values and find some combination with a Simpson's reversal. We'll generate a dataset with a positive probability difference in each sub-population, then filter out anything that also has a non-negative population difference. 

```{r params}
set.seed(8168)

N <- 10000

part_c <- tibble(
  id = 1:N %>% as.integer(),
  
  r = rbeta(N, 2, 2),   # P(Z = 1)
  
  q0 = rbeta(N, 2, 2),  # P(X = 1 | Z = 0)
  q1 = rbeta(N, 2, 2),  # P(X = 1 | Z = 1)
  
  p00 = rbeta(N, 2, 2), # P(Y = 1 | X = 0, Z = 0)
  p10 = rbeta(N, 2, 2) * (p00 - 1) + 1, # P(Y = 1 | X = 1, Z = 0)
  p01 = rbeta(N, 2, 2), # P(Y = 1 | X = 0, Z = 1)
  p11 = rbeta(N, 2, 2) * (p01 - 1) + 1, # P(Y = 1 | X = 1, Z = 1)
  
  diff_pop = (p10 * q0 * (1 - r) + p11 * q1 * r) / (q0 * (1 - r) + q1 * r) - (p00 * (1 - q0) * (1 - r) + p01 * (1 - q1) * r) / ((1 - q0) * (1 - r) + (1 - q1) * r),
  diff_z0 = p10 - p00,
  diff_z1 = p11 - p01
) 
```

As a check, there should be no rows with a non-positive difference.

```{r part_c_check}
check <- part_c %>% 
  filter(diff_z0 <= 0 | diff_z1 <= 0) %>% 
  nrow()

# throw error if there are rows
stopifnot(check == 0)

check
```

Now we simply throw away any rows with a non-negative population difference. Here is one combination of parameters exhibiting Simpson's reversal.

```{r simpsons_reversal}
simpsons_reversal <- part_c %>% 
  filter(diff_pop < -0.05) %>% 
  head(1) %>% 
  gather(term, value)
```

```{r simpsons_reversal_table, echo=FALSE}
simpsons_reversal %>% 
  kable(caption = "Parameters leading to Simpson's reversal") %>% 
  kable_styling(bootstrap_options = c('hover', 'striped', 'responsive'))
```

As a final check, let's generate a dataset for this set of parameters.

```{r data}
df <- simpsons_reversal %>% 
  spread(term, value) %>% 
  crossing(unit = 1:N) %>% 
  mutate(
    z = rbinom(N, 1, r),
    x = rbinom(N, 1, if_else(z == 0, q0, q1)),
    p_y_given_x_z = case_when(
      x == 0 & z == 0 ~ p00,
      x == 0 & z == 1 ~ p01,
      x == 1 & z == 0 ~ p10,
      x == 1 & z == 1 ~ p11
    ),
    y = rbinom(N, 1, p_y_given_x_z)
  ) %>% 
  select(unit, x, y, z)

```

The empirical joint probability distribution is as follows.

```{r joint_probability}
p_x_y_z <- df %>% 
  group_by(x, y, z) %>% 
  count() %>% 
  ungroup() %>% 
  mutate(p = n / sum(n))

```

```{r joint_probability_table, echo=FALSE}
p_x_y_z %>% 
  kable() %>% 
  kable_styling(bootstrap_options = c('hover', 'striped', 'responsive'))
```

The population-level probability difference is given by:


```{r diff_pop}
diff_pop <- p_x_y_z %>% 
  group_by(x) %>% 
  summarise(p = sum(n * y) / sum(n)) %>% 
  spread(x, p) %>%
  mutate(diff = `1` - `0`)

```


```{r diff_pop_table, echo=FALSE}
diff_pop %>% 
  kable() %>% 
  kable_styling(bootstrap_options = c('hover', 'striped', 'responsive'))
```

which is close to the theoretical value.


Similarly, the sub-population differences are

```{r diff_z}
diff_z <- p_x_y_z %>% 
  group_by(x, z) %>% 
  summarise(p = sum(n * y) / sum(n)) %>% 
  spread(x, p) %>% 
  mutate(diff = `1` - `0`)
```

```{r diff_z_table, echo=FALSE}
diff_z %>% 
  kable() %>% 
  kable_styling(bootstrap_options = c('hover', 'striped', 'responsive'))
```

which are also close to the theoretical values we calculated. More importantly, they have a different sign to the population difference, confiming that we have case of Simpson's reversal.
