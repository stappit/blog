---
title: "BDA3 Chapter 5 Exercise 13"
author: "Brian Callander"
date: "2019-02-03"
tags: bda chapter 3, solutions
tldr: "Here's my solution to exercise 13, chapter 5, of Gelman's Bayesian Data Analysis (BDA), 3rd edition."
always_allow_html: yes
output: 
  md_document:
    variant: markdown
    preserve_yaml: yes
---

Here's my solution to exercise 13, chapter 5, of [Gelman's](https://andrewgelman.com/) *Bayesian Data Analysis* (BDA), 3rd edition. There are [solutions](http://www.stat.columbia.edu/~gelman/book/solutions.pdf) to some of the exercises on the [book's webpage](http://www.stat.columbia.edu/~gelman/book/).

<!--more-->

<div style="display:none">
  $\DeclareMathOperator{\dbinomial}{Binomial}
   \DeclareMathOperator{\dbern}{Bernoulli}
   \DeclareMathOperator{\dpois}{Poisson}
   \DeclareMathOperator{\dnorm}{Normal}
   \DeclareMathOperator{\dt}{t}
   \DeclareMathOperator{\dcauchy}{Cauchy}
   \DeclareMathOperator{\dexponential}{Exp}
   \DeclareMathOperator{\duniform}{Uniform}
   \DeclareMathOperator{\dgamma}{Gamma}
   \DeclareMathOperator{\dinvgamma}{InvGamma}
   \DeclareMathOperator{\invlogit}{InvLogit}
   \DeclareMathOperator{\logit}{Logit}
   \DeclareMathOperator{\ddirichlet}{Dirichlet}
   \DeclareMathOperator{\dbeta}{Beta}$
</div>

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  comment = NA,
  message = FALSE,
  warning = FALSE,
  error = TRUE,
  # cache = TRUE,
  dev = "svglite"
)

library(tidyverse)
library(scales)
library(kableExtra)

library(rstan)
library(tidybayes)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

theme_set(theme_bw())

```

```{r data}
df <- read_csv('data/chapter_03_exercise_08.csv') %>% 
  filter(type == 'residential' & bike_route) %>% 
  transmute(
    i = 1:n(),
    bikes,
    other,
    total = bikes + other,
    rate = bikes / total
  )
```

```{r data_table, echo=FALSE}
df %>% 
  kable(caption = 'Subset of table 3.3 restricted to residential streets that are bike routes') %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "responsive"))
```

We'll use the prior on $\alpha$, $\beta$ given in equation 5.9 and implement it in [Stan](https://mc-stan.org/). Note that stan works on the log scale, so we increment the posterior density (= `target`) by $\log\left( (\alpha + \beta)^{-\frac{5}{2}} \right) = -\frac{5}{2}\log(\alpha + \beta)$. Here is the [model code](src/ex_05_13.stan):

```{r model}
model <- rstan::stan_model('src/ex_05_13.stan')
```

```{r model_code, echo=FALSE}
model
```

Now we calculate the posterior, using [tidybayes](https://mjskay.github.io/tidybayes/) to take care of passing the data to stan.

```{r fit, results='hide'}
fit <- model %>% 
  rstan::sampling(data = tidybayes::compose_data(df)) %>% 
  tidybayes::recover_types(df)
```

We don't show any diagnostics here, but there are no divergences, the rhat is very close to 1, the effective sample size is large, and the traces look reasonable.

Now we can draw some samples from the posterior.

```{r}
draws <- fit %>% 
  tidybayes::spread_draws(alpha, beta, theta[i]) 
```

```{r hyperprior_plot, echo=FALSE, fig.cap="Contour plot of the marginal posterior density of (log(α/β), log(α + β)) for the residential bike route example."}
draws %>% 
  filter(i == 1) %>% 
  ggplot() + 
  aes(x = log(alpha / beta), y = log(alpha + beta)) +
  geom_hex(aes(colour = ..count..), binwidth=0.1) +
  labs(
    x = 'log(α / β)',
    y = 'log(α + β)',
    title = 'Contour plot of the marginal posterior density'
  )
```

We can also use our posterior draws to plot the observed (= unpooled) rates against the estimated rates. In this case, there are no large differences, although smaller rates seem to be estimated slightly higher than observed and larger rates lower than observed. All observed rates are within the posterior intervals of the estimates.

```{r estimate_vs_observed_plot, echo=FALSE, fig.cap='Posterior medians and 95% intervals of bike observation rates based on simulations from the join posterior distribution.' }
draws %>% 
  median_qi() %>% 
  inner_join(df, by = 'i') %>%
  ggplot() +
  aes(x = rate, ymin = theta.lower, y = theta, ymax = theta.upper) +
  geom_abline(slope = 1, intercept = 0, linetype = 'dashed', colour = 'chocolate') +
  geom_pointinterval() +
  scale_x_continuous(limits = c(0, NA), labels = percent) +
  scale_y_continuous(limits = c(0, NA), labels = percent) +
  labs(
    y = 'Estimated parameter',
    x = 'Observed rate',
    title = 'Comparison of estimated rates with observed rates',
    subtitle = 'The dotted line corresponds to the unpooled estimates'
  )
    
```

To calculate a posterior interval for the average underlying proportion of bike traffic, we sample $\alpha, \beta$ from the posterior, then draw a new $\tilde\theta \sim \dbeta(\alpha, \beta)$. It wouldn't be correct to use the values of $\theta_j$ from the model parameters, since those are estimates from known streets.  If we also want an estimate of the number of bikes observed on a new street (where 100 total vehicles go by), then we draw $\tilde y \sim \dbinomial(100, \tilde\theta)$ . The posterior intervals are then just the desired quantiles of the drawn parameters.

```{r cis}
cis <- draws %>% 
  filter(i == 1) %>% 
  mutate(
    theta = rbeta(n(), alpha, beta),
    y = rbinom(n(), 100, theta)
  ) %>% 
  tidybayes::median_qi() %>% 
  select(matches('y|theta')) 
```

```{r hits, include=FALSE}
hits <- df %>% 
  crossing(cis) %>% 
  transmute(
    theta_hit = theta.lower <= rate & rate <= theta.upper,
    y_hit = y.lower <= bikes & bikes <= y.upper
  ) %>% 
  summarise_all(sum)
  
```

The 95% posterior interval for $\tilde\theta$ is (`r cis %>% pull(theta.lower) %>% percent()`, `r cis %>% pull(theta.upper) %>% percent`), which includes `r hits %>% pull(theta_hit)` of the 10 observed rates. The 95% posterior interval of $\tilde y$ is (`r cis %>% pull(y.lower)`, `r cis %>% pull(y.upper)`), which includes `r hits %>% pull(y_hit)` of the 10 observed values. These intervals seem reasonable, although they are fairly wide. It's difficult to make a statement about how useful these could be in application without a concrete idea of what that application is.


